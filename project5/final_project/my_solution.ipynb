{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/schoolboy/miniconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bonus': 64,\n",
       " 'deferral_payments': 107,\n",
       " 'deferred_income': 97,\n",
       " 'director_fees': 129,\n",
       " 'email_address': 35,\n",
       " 'exercised_stock_options': 44,\n",
       " 'expenses': 51,\n",
       " 'from_messages': 60,\n",
       " 'from_poi_to_this_person': 60,\n",
       " 'from_this_person_to_poi': 60,\n",
       " 'loan_advances': 142,\n",
       " 'long_term_incentive': 80,\n",
       " 'other': 53,\n",
       " 'poi': 0,\n",
       " 'restricted_stock': 36,\n",
       " 'restricted_stock_deferred': 128,\n",
       " 'salary': 51,\n",
       " 'shared_receipt_with_poi': 60,\n",
       " 'to_messages': 60,\n",
       " 'total_payments': 21,\n",
       " 'total_stock_value': 20}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "### Task 1: Select what features you'll use.\n",
    "### features_list is a list of strings, each of which is a feature name.\n",
    "### The first feature must be \"poi\".\n",
    "features_list = ['poi','salary'] # You will need to use more features\n",
    "\n",
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n",
    "\n",
    "### Task 2: Remove outliers\n",
    "\n",
    "my_dataset = data_dict\n",
    "\n",
    "\n",
    "# missing value count \n",
    "total_feature = my_dataset['ALLEN PHILLIP K'].keys()\n",
    "feature_count_dict = {}\n",
    "for val in range(0,len(total_feature)):\n",
    "    feature_count_dict[total_feature[val]] = 0\n",
    "poi_count = 0\n",
    "for val in my_dataset:\n",
    "    for key in my_dataset[val]:\n",
    "        if key == 'poi':\n",
    "            if my_dataset[val][key] == True:\n",
    "                poi_count+=1\n",
    "        if my_dataset[val][key] == 'NaN':\n",
    "            feature_count_dict[key]+=1\n",
    "# total length of data\n",
    "print len(my_dataset)\n",
    "# true poi count\n",
    "print poi_count\n",
    "# feature nan count\n",
    "feature_count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# removing feature which has NaN value more than 100\n",
    "total_feature.remove('deferred_income')\n",
    "total_feature.remove('director_fees')\n",
    "total_feature.remove('loan_advances')\n",
    "total_feature.remove('restricted_stock_deferred')\n",
    "total_feature.remove('email_address')\n",
    "total_feature.remove('poi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# new feature formation \n",
    "### Task 3: Create new feature(s)\n",
    "### Store to my_dataset for easy export below.\n",
    "for name in my_dataset:\n",
    "    if (all([\n",
    "        my_dataset[name]['from_messages'] != 'NaN',\n",
    "        my_dataset[name]['from_this_person_to_poi'] != 'NaN',\n",
    "        my_dataset[name]['to_messages'] != 'NaN',\n",
    "        my_dataset[name]['from_poi_to_this_person'] != 'NaN'\n",
    "    ])):\n",
    "        my_dataset[name]['from_fraction'] = float(my_dataset[name]['from_poi_to_this_person']) / float(my_dataset[name]['to_messages'])\n",
    "        my_dataset[name]['to_fraction'] = float(my_dataset[name]['from_this_person_to_poi']) / float(my_dataset[name]['from_messages'])\n",
    "    else:\n",
    "        my_dataset[name]['from_fraction'] = 0\n",
    "        my_dataset[name]['to_fraction'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_feature.insert(0,'from_fraction')\n",
    "total_feature.insert(0,'to_fraction')\n",
    "my_features = total_feature\n",
    "data = featureFormat(my_dataset, my_features, sort_keys = True)\n",
    "\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['from_poi_to_this_person',\n",
       " 'from_this_person_to_poi',\n",
       " 'from_messages',\n",
       " 'shared_receipt_with_poi',\n",
       " 'to_messages']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_features = total_feature\n",
    "k_best = SelectKBest(k=5)\n",
    "k_best.fit(features, labels)\n",
    "results_list = zip(k_best.get_support(), my_features[1:])\n",
    "best_features = []\n",
    "for i in range(0,len(results_list)):\n",
    "    if results_list[i][0] == True:\n",
    "        best_features.insert(0,results_list[i][1])\n",
    "best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator\n",
      "LinearSVC(C=100, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.95      0.86        20\n",
      "        1.0       0.75      0.38      0.50         8\n",
      "\n",
      "avg / total       0.78      0.79      0.76        28\n",
      "\n",
      "best estimator\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=5,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00        21\n",
      "        1.0       1.00      1.00      1.00         7\n",
      "\n",
      "avg / total       1.00      1.00      1.00        28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Task 4: Try a varity of classifiers\n",
    "### Please name your classifier clf for easy export below.\n",
    "### Note that if you want to do PCA or other multi-stage operations,\n",
    "### you'll need to use Pipelines. For more info:\n",
    "### http://scikit-learn.org/stable/modules/pipeline.html\n",
    "\n",
    "# Provided to give you a starting point. Try a variety of classifiers.\n",
    "\n",
    "\n",
    "### Task 5: Tune your classifier to achieve better than .3 precision and recall\n",
    "data = featureFormat(my_dataset, best_features, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score,classification_report\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import svm\n",
    "def evaluate_clf(clf,params,feature,lable):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(feature, lable,train_size=.7)\n",
    "    clf= GridSearchCV(clf, params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print \"best estimator\"\n",
    "    print clf.best_estimator_\n",
    "    y_pred = clf.predict(X_test)\n",
    "    precision = []\n",
    "    recall = []\n",
    "    print classification_report(y_test,y_pred)\n",
    "'''    for i in range(0,len(y_test)):\n",
    "        #precision.append(precision_score(y_test[i],y_pred[i]))\n",
    "        #recall.append(recall_score(y_test[i],y_pred[i]))\n",
    "        print precision_score(y_test[i],y_pred[i])\n",
    "    print mean(recall)\n",
    "    print mean(precision)\n",
    " '''\n",
    "best_features.insert(0,'poi')\n",
    "#clf.fit()\n",
    "lsvc=svm.LinearSVC(penalty='l2')\n",
    "evaluate_clf(lsvc,[{'C':[1,10,100]}],features,labels)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rforest = RandomForestClassifier(n_estimators = 10)\n",
    "# min samples leaf is used to determine \n",
    "evaluate_clf(rforest,[{'min_samples_leaf':[5,10,20]}],features,labels)\n",
    "rforest = RandomForestClassifier(n_estimators = 10,min_samples_leaf = 5)\n",
    "dump_classifier_and_data(rforest, my_dataset, best_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
